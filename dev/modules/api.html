
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>API reference &#8212; TensorLy-Torch 0.3.0 documentation</title> 
<link rel="stylesheet" href="../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tensorly_style.css" />

  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
 <script src="../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QSPLEF75VT');
</script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="tltorch.FactorizedTensor" href="generated/tltorch.FactorizedTensor.html" />
    <link rel="prev" title="Installing tensorly-Torch" href="../install.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        

          <a class="navbar-item" href="../index.html">
			      
            <img src="../_static/tensorly-torch-logo.png" height="28">
            
          </a>
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/torch" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        

          <div class="navbar-start">
            
              <a class="navbar-item" href="../install.html">
              Install
            </a>
              <a class="navbar-item" href="../user_guide/index.html">
              User Guide
            </a>
              <a class="navbar-item" href="#">
              API
            </a>
              <a class="navbar-item" href="../about.html">
              About Us
            </a>
            <div class="navbar-item has-dropdown is-hoverable is-boxed">
              <a class="navbar-link">
                Ecosystem
              </a>
              <div class="navbar-dropdown top-navbar">
                <a class="navbar-item" href="http://tensorly.org/dev" target="_blank">
                  TensorLy
                </a>
                <a class="navbar-item" href="http://tensorly.org/viz" target="_blank">
                  TensorLy-Viz
                </a>
                <a class="navbar-item" href="http://tensorly.org/quantum" target="_blank">
                  TensorLy-Quantum
                </a>
              </div>
            </div>
          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/torch" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
            </a>

            </div> 
          </div> 
        </div> 

      </nav>
      
    </navbar>
  </header>


  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
  
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search TensorLy-Torch" name="q" aria-labelledby="searchlabel">
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>$('#searchbox').show(0);</script>
  <script>
  $(document).ready(function() {
    Document.highlightSearchWords = function() {
      var params = $.getQueryParameters();
      var terms = (params.highlight) ? params.highlight[0].split(/\s+/) : [];
      if (terms.length) {
        var body = $('div.body');
        if (!body.length) {
          body = $('body');
        }
        window.setTimeout(function() {
          $.each(terms, function() {
            body.highlightText(this.toLowerCase(), 'highlighted');
          });
        }, 10);
        $('<p class="highlight-link"><a href="javascript:Documentation.' +
          'hideSearchWords()">' + _('Hide All')
          + '<span class="tag is-delete"></span>'
          + '</a></p>')
            .appendTo($('#searchbox'));
      }
    };
  });
  </script>
</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing tensorly-Torch</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#factorized-tensors">Factorized Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensorized-matrices">Tensorized Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tltorch.factorized_tensors">Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tltorch.factorized_layers">Tensor Regression Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensor-contraction-layers">Tensor Contraction Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#factorized-linear-layers">Factorized Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#factorized-convolutions">Factorized Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#factorized-embeddings">Factorized Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tltorch.tensor_hooks">Tensor Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="#l1-regularization">L1 Regularization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About Us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

  <div class="column main-column">

    
    <div class="main-section">

      
      
      <div class="side-menu-toggle">
        <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
          <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
          <span>menu</span> 
        </button>
      </div>
      

      <div class="container content main-content">
        
  <section id="api-reference">
<h1>API reference</h1>
<p><a class="reference internal" href="#module-tltorch" title="tltorch"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tltorch</span></code></a>: Tensorized Deep Neural Networks</p>
<span class="target" id="module-tltorch"></span><section id="factorized-tensors">
<span id="factorized-tensor-ref"></span><h2>Factorized Tensors</h2>
<p>TensorLy-Torch builds on top of TensorLy and provides out of the box PyTorch layers for tensor based operations.
The core of this is the concept of factorized tensors, which factorize our layers, instead of regular, dense PyTorch tensors.</p>
<p>You can create any factorized tensor through the main class using:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.FactorizedTensor.html#tltorch.FactorizedTensor" title="tltorch.FactorizedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Tensor in Factorized form</p></td>
</tr>
</tbody>
</table>
<p>You can create a tensor of any form using <code class="docutils literal notranslate"><span class="pre">FactorizedTensor.new(shape,</span> <span class="pre">rank,</span> <span class="pre">factorization)</span></code>, where factorization can be <cite>Dense</cite>, <cite>CP</cite>, <cite>Tucker</cite> or <cite>TT</cite>.
Note that if you use <code class="docutils literal notranslate"><span class="pre">factorization</span> <span class="pre">=</span> <span class="pre">'dense'</span></code> you are just creating a regular, unfactorized tensor.
This allows to manipulate any tensor, factorized or not, with a simple, unified interface.</p>
<p>Alternatively, you can also directly create a specific subclass:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.DenseTensor.html#tltorch.DenseTensor" title="tltorch.DenseTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Dense tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.CPTensor.html#tltorch.CPTensor" title="tltorch.CPTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CPTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>CP Factorization</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.TuckerTensor.html#tltorch.TuckerTensor" title="tltorch.TuckerTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TuckerTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Tucker Factorization</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.TTTensor.html#tltorch.TTTensor" title="tltorch.TTTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TTTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Tensor-Train (Matrix-Product-State) Factorization</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tensorized-matrices">
<span id="factorized-matrix-ref"></span><h2>Tensorized Matrices</h2>
<dl class="simple">
<dt>In TensorLy-Torch , you can also represent matrices in <em>tensorized</em> form, as low-rank tensors.</dt><dd><p>Just as for factorized tensor, you can create a tensorized matrix through the main class using:</p>
</dd>
</dl>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.TensorizedTensor.html#tltorch.TensorizedTensor" title="tltorch.TensorizedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorizedTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Matrix in Tensorized Format</p></td>
</tr>
</tbody>
</table>
<p>You can create a tensor of any form using <code class="docutils literal notranslate"><span class="pre">TensorizedTensor.new(tensorized_shape,</span> <span class="pre">rank,</span> <span class="pre">factorization)</span></code>, where factorization can be <cite>Dense</cite>, <cite>CP</cite>, <cite>Tucker</cite> or <cite>BlockTT</cite>.</p>
<p>You can also explicitly create the type of tensor you want using the following classes:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.DenseTensorized.html#tltorch.DenseTensorized" title="tltorch.DenseTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseTensorized</span></code></a>(*args,Â **kwargs)</p></td>
<td><p><p class="rubric">Methods</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.TensorizedTensor.html#tltorch.TensorizedTensor" title="tltorch.TensorizedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorizedTensor</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Matrix in Tensorized Format</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.CPTensorized.html#tltorch.CPTensorized" title="tltorch.CPTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CPTensorized</span></code></a>(*args,Â **kwargs)</p></td>
<td><p><p class="rubric">Methods</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.BlockTT.html#tltorch.BlockTT" title="tltorch.BlockTT"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BlockTT</span></code></a>(*args,Â **kwargs)</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tltorch.factorized_tensors">
<span id="initialization"></span><span id="init-ref"></span><h2>Initialization</h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.tensor_init.html#tltorch.factorized_tensors.init.tensor_init" title="tltorch.factorized_tensors.init.tensor_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_init</span></code></a>(tensor[,Â std])</p></td>
<td><p>Initializes directly the parameters of a factorized tensor so the reconstruction has the specified standard deviation and 0 mean</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.cp_init.html#tltorch.factorized_tensors.init.cp_init" title="tltorch.factorized_tensors.init.cp_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cp_init</span></code></a>(cp_tensor[,Â std])</p></td>
<td><p>Initializes directly the weights and factors of a CP decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.tucker_init.html#tltorch.factorized_tensors.init.tucker_init" title="tltorch.factorized_tensors.init.tucker_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_init</span></code></a>(tucker_tensor[,Â std])</p></td>
<td><p>Initializes directly the weights and factors of a Tucker decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.tt_init.html#tltorch.factorized_tensors.init.tt_init" title="tltorch.factorized_tensors.init.tt_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tt_init</span></code></a>(tt_tensor[,Â std])</p></td>
<td><p>Initializes directly the weights and factors of a TT decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.block_tt_init.html#tltorch.factorized_tensors.init.block_tt_init" title="tltorch.factorized_tensors.init.block_tt_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">block_tt_init</span></code></a>(block_tt[,Â std])</p></td>
<td><p>Initializes directly the weights and factors of a BlockTT decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tltorch.factorized_layers">
<span id="tensor-regression-layers"></span><span id="trl-ref"></span><h2>Tensor Regression Layers</h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.TRL.html#tltorch.factorized_layers.TRL" title="tltorch.factorized_layers.TRL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TRL</span></code></a>(input_shape,Â output_shape[,Â bias,Â ...])</p></td>
<td><p>Tensor Regression Layers</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tensor-contraction-layers">
<span id="tcl-ref"></span><h2>Tensor Contraction Layers</h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.TCL.html#tltorch.factorized_layers.TCL" title="tltorch.factorized_layers.TCL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TCL</span></code></a>(input_shape,Â rank[,Â verbose,Â bias,Â ...])</p></td>
<td><p>Tensor Contraction Layer <a class="reference internal" href="generated/tltorch.factorized_layers.TCL.html#r4c5b93526459-1" id="id1"><span>[R4c5b93526459-1]</span></a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="factorized-linear-layers">
<span id="factorized-linear-ref"></span><h2>Factorized Linear Layers</h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.FactorizedLinear.html#tltorch.factorized_layers.FactorizedLinear" title="tltorch.factorized_layers.FactorizedLinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedLinear</span></code></a>(in_tensorized_features,Â ...)</p></td>
<td><p>Tensorized Fully-Connected Layers</p></td>
</tr>
</tbody>
</table>
</section>
<section id="factorized-convolutions">
<span id="factorized-conv-ref"></span><h2>Factorized Convolutions</h2>
<p>General N-Dimensional convolutions in Factorized forms</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.FactorizedConv.html#tltorch.factorized_layers.FactorizedConv" title="tltorch.factorized_layers.FactorizedConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedConv</span></code></a>(in_channels,Â out_channels,Â ...)</p></td>
<td><p>Create a factorized convolution of arbitrary order</p></td>
</tr>
</tbody>
</table>
</section>
<section id="factorized-embeddings">
<span id="tensor-dropout-ref"></span><h2>Factorized Embeddings</h2>
<p>A drop-in replacement for PyTorchâs embeddings but using an efficient tensor parametrization that never reconstructs the full table.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.FactorizedEmbedding.html#tltorch.factorized_layers.FactorizedEmbedding" title="tltorch.factorized_layers.FactorizedEmbedding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedEmbedding</span></code></a>(num_embeddings,Â ...[,Â ...])</p></td>
<td><p>Tensorized Embedding Layers For Efficient Model Compression Tensorized drop-in replacement for <cite>torch.nn.Embedding</cite></p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tltorch.tensor_hooks">
<span id="tensor-dropout"></span><span id="id2"></span><h2>Tensor Dropout</h2>
<p>These functions allow you to easily add or remove tensor dropout from tensor layers.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.tensor_dropout.html#tltorch.tensor_hooks.tensor_dropout" title="tltorch.tensor_hooks.tensor_dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_dropout</span></code></a>(factorized_tensor[,Â p,Â ...])</p></td>
<td><p>Tensor Dropout</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.remove_tensor_dropout.html#tltorch.tensor_hooks.remove_tensor_dropout" title="tltorch.tensor_hooks.remove_tensor_dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_tensor_dropout</span></code></a>(factorized_tensor)</p></td>
<td><p>Removes the tensor dropout from a TensorModule</p></td>
</tr>
</tbody>
</table>
<p>You can also use the class API below but unless you have a particular use for the classes, you should use the convenient functions provided instead.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.TensorDropout.html#tltorch.tensor_hooks.TensorDropout" title="tltorch.tensor_hooks.TensorDropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDropout</span></code></a>(proba[,Â min_dim,Â min_values,Â ...])</p></td>
<td><p>Decomposition Hook for Tensor Dropout on FactorizedTensor</p></td>
</tr>
</tbody>
</table>
</section>
<section id="l1-regularization">
<span id="tensor-lasso-ref"></span><h2>L1 Regularization</h2>
<p>L1 Regularization on tensor modules.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.tensor_lasso.html#tltorch.tensor_hooks.tensor_lasso" title="tltorch.tensor_hooks.tensor_lasso"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_lasso</span></code></a>([factorization,Â penalty,Â ...])</p></td>
<td><p>Generalized Tensor Lasso from a factorized tensors</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.remove_tensor_lasso.html#tltorch.tensor_hooks.remove_tensor_lasso" title="tltorch.tensor_hooks.remove_tensor_lasso"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_tensor_lasso</span></code></a>(factorized_tensor)</p></td>
<td><p>Removes the tensor lasso from a TensorModule</p></td>
</tr>
</tbody>
</table>
</section>
</section>


      </div>

      
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button pagination-previous" href="../install.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Installing tensorly-Torch</span>
    </a>
    
    
    <a class="button pagination-next" href="generated/tltorch.FactorizedTensor.html" title="next page" accesskey="n">
        <span><code class="xref py py-mod docutils literal notranslate"><span class="pre">tltorch</span></code>.FactorizedTensor </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

      

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2022, Jean Kossaifi.<br/>
        </div>
      <div class="block">
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> and the <a href="http://tensorly.org"><strong>TensorLy</strong></a> theme by <a href="http://jeankossaifi.com">Jean Kossaifi</a>.
      </div>
    </div>
  </footer>

    </div>

  </div>  

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc"> 
        <p class="menu-label"> 
            <span class="icon-text">
                <span class="icon"><i class="fas fa-duotone fa-list"></i></span>
                <span> On this page </span>
            </span>
        </p>

        <div class="menu menu-list localtoc-list">
        <ul>
<li><a class="reference internal" href="#">API reference</a><ul>
<li><a class="reference internal" href="#factorized-tensors">Factorized Tensors</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#tensorized-matrices">Tensorized Matrices</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-tltorch.factorized_tensors">Initialization</a></li>
<li><a class="reference internal" href="#module-tltorch.factorized_layers">Tensor Regression Layers</a></li>
<li><a class="reference internal" href="#tensor-contraction-layers">Tensor Contraction Layers</a></li>
<li><a class="reference internal" href="#factorized-linear-layers">Factorized Linear Layers</a></li>
<li><a class="reference internal" href="#factorized-convolutions">Factorized Convolutions</a></li>
<li><a class="reference internal" href="#factorized-embeddings">Factorized Embeddings</a></li>
<li><a class="reference internal" href="#module-tltorch.tensor_hooks">Tensor Dropout</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#l1-regularization">L1 Regularization</a></li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

  

  </div>  
  </div> 

  
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>