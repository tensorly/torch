<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>API reference &#8212; TensorLy-Torch 0.4.0 documentation</title> 
<link rel="stylesheet" href="../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/tensorly_style.css?v=a02e9698" />

  
    <script src="../_static/documentation_options.js?v=6c02275b"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
 <script src="../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QSPLEF75VT');
</script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="tltorch.FactorizedTensor" href="generated/tltorch.FactorizedTensor.html" />
    <link rel="prev" title="Installing tensorly-Torch" href="../install.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        

          <a class="navbar-item" href="../index.html">
            <img src="../_static/tensorly-torch-logo.png" height="28">
          </a>
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/torch" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        

          <div class="navbar-start">
            
              <a class="navbar-item" href="../install.html">
              Install
            </a>
              <a class="navbar-item" href="../user_guide/index.html">
              User Guide
            </a>
              <a class="navbar-item" href="#">
              API
            </a>
              <a class="navbar-item" href="../about.html">
              About Us
            </a>
            <div class="navbar-item has-dropdown is-hoverable is-boxed">
              <a class="navbar-link">
                Ecosystem
              </a>
              <div class="navbar-dropdown top-navbar">
                <a class="navbar-item" href="http://tensorly.org/dev" target="_blank">
                  TensorLy
                </a>
                <a class="navbar-item" href="http://tensorly.org/viz" target="_blank">
                  TensorLy-Viz
                </a>
                <a class="navbar-item" href="http://tensorly.org/quantum" target="_blank">
                  TensorLy-Quantum
                </a>
              </div>
            </div>
          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/torch" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
            </a>

            </div> 
          </div> 
        </div> 

      </nav>
      
    </navbar>
  </header>


  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
  
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search TensorLy-Torch" name="q" aria-labelledby="searchlabel autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>document.getElementById('searchbox').style.display = "block"</script>

</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing tensorly-Torch</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#factorized-tensors">Factorized Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensorized-matrices">Tensorized Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#complex-tensors">Complex Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tltorch.factorized_tensors">Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tltorch.factorized_layers">Tensor Regression Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensor-contraction-layers">Tensor Contraction Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#factorized-linear-layers">Factorized Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#factorized-convolutions">Factorized Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#factorized-embeddings">Factorized Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tltorch.tensor_hooks">Tensor Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="#l1-regularization">L1 Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#utilities">Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About Us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

  <div class="column main-column">

    
    <div class="main-section">

      
      
      <div class="side-menu-toggle">
        <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
          <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
          <span>menu</span> 
        </button>
      </div>
      

      <div class="container content main-content">
        
  <section id="api-reference">
<h1>API reference<a class="headerlink" href="#api-reference" title="Link to this heading">¶</a></h1>
<p><a class="reference internal" href="#module-tltorch" title="tltorch"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tltorch</span></code></a>: Tensorized Deep Neural Networks</p>
<span class="target" id="module-tltorch"></span><section id="factorized-tensors">
<span id="factorized-tensor-ref"></span><h2>Factorized Tensors<a class="headerlink" href="#factorized-tensors" title="Link to this heading">¶</a></h2>
<p>TensorLy-Torch builds on top of TensorLy and provides out of the box PyTorch layers for tensor based operations.
The core of this is the concept of factorized tensors, which factorize our layers, instead of regular, dense PyTorch tensors.</p>
<p>You can create any factorized tensor through the main class using:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.FactorizedTensor.html#tltorch.FactorizedTensor" title="tltorch.FactorizedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Tensor in Factorized form</p></td>
</tr>
</tbody>
</table>
<p>You can create a tensor of any form using <code class="docutils literal notranslate"><span class="pre">FactorizedTensor.new(shape,</span> <span class="pre">rank,</span> <span class="pre">factorization)</span></code>, where factorization can be <cite>Dense</cite>, <cite>CP</cite>, <cite>Tucker</cite> or <cite>TT</cite>.
Note that if you use <code class="docutils literal notranslate"><span class="pre">factorization</span> <span class="pre">=</span> <span class="pre">'dense'</span></code> you are just creating a regular, unfactorized tensor.
This allows to manipulate any tensor, factorized or not, with a simple, unified interface.</p>
<p>Alternatively, you can also directly create a specific subclass:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.DenseTensor.html#tltorch.DenseTensor" title="tltorch.DenseTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Dense tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.CPTensor.html#tltorch.CPTensor" title="tltorch.CPTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CPTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>CP Factorization</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.TuckerTensor.html#tltorch.TuckerTensor" title="tltorch.TuckerTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TuckerTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Tucker Factorization</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.TTTensor.html#tltorch.TTTensor" title="tltorch.TTTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TTTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Tensor-Train (Matrix-Product-State) Factorization</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tensorized-matrices">
<span id="factorized-matrix-ref"></span><h2>Tensorized Matrices<a class="headerlink" href="#tensorized-matrices" title="Link to this heading">¶</a></h2>
<dl class="simple">
<dt>In TensorLy-Torch , you can also represent matrices in <em>tensorized</em> form, as low-rank tensors.</dt><dd><p>Just as for factorized tensor, you can create a tensorized matrix through the main class using:</p>
</dd>
</dl>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.TensorizedTensor.html#tltorch.TensorizedTensor" title="tltorch.TensorizedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorizedTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Matrix in Tensorized Format</p></td>
</tr>
</tbody>
</table>
<p>You can create a tensor of any form using <code class="docutils literal notranslate"><span class="pre">TensorizedTensor.new(tensorized_shape,</span> <span class="pre">rank,</span> <span class="pre">factorization)</span></code>, where factorization can be <cite>Dense</cite>, <cite>CP</cite>, <cite>Tucker</cite> or <cite>BlockTT</cite>.</p>
<p>You can also explicitly create the type of tensor you want using the following classes:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.DenseTensorized.html#tltorch.DenseTensorized" title="tltorch.DenseTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseTensorized</span></code></a>(*args, **kwargs)</p></td>
<td><p><p class="rubric">Methods</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.TensorizedTensor.html#tltorch.TensorizedTensor" title="tltorch.TensorizedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorizedTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Matrix in Tensorized Format</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.CPTensorized.html#tltorch.CPTensorized" title="tltorch.CPTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CPTensorized</span></code></a>(*args, **kwargs)</p></td>
<td><p><p class="rubric">Methods</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.BlockTT.html#tltorch.BlockTT" title="tltorch.BlockTT"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BlockTT</span></code></a>(*args, **kwargs)</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
</tbody>
</table>
</section>
<section id="complex-tensors">
<span id="complex-ref"></span><h2>Complex Tensors<a class="headerlink" href="#complex-tensors" title="Link to this heading">¶</a></h2>
<p>In theory, you can simply specify <code class="docutils literal notranslate"><span class="pre">dtype=torch.cfloat</span></code> in the creation of any of the tensors of tensorized matrices above, to automatically create a complex valued tensor.
However, in practice, there are many issues in complex support. Distributed Data Parallelism in particular, is not supported.</p>
<p>In TensorLy-Torch, we propose a convenient and transparent way around this: simply use <code class="docutils literal notranslate"><span class="pre">ComplexTensor</span></code> instead.
This will store the factors of the decomposition in real form (by explicitly storing the real and imaginary parts)
but will transparently return you a complex valued tensor or reconstruction.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.ComplexDenseTensor.html#tltorch.ComplexDenseTensor" title="tltorch.ComplexDenseTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexDenseTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex Dense Factorization</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.ComplexCPTensor.html#tltorch.ComplexCPTensor" title="tltorch.ComplexCPTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexCPTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex CP Factorization</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.ComplexTuckerTensor.html#tltorch.ComplexTuckerTensor" title="tltorch.ComplexTuckerTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexTuckerTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex Tucker Factorization</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.ComplexTTTensor.html#tltorch.ComplexTTTensor" title="tltorch.ComplexTTTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexTTTensor</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex TT Factorization</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.ComplexDenseTensorized.html#tltorch.ComplexDenseTensorized" title="tltorch.ComplexDenseTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexDenseTensorized</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex DenseTensorized Factorization</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.ComplexTuckerTensorized.html#tltorch.ComplexTuckerTensorized" title="tltorch.ComplexTuckerTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexTuckerTensorized</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex TuckerTensorized Factorization</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.ComplexCPTensorized.html#tltorch.ComplexCPTensorized" title="tltorch.ComplexCPTensorized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexCPTensorized</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex Tensorized CP Factorization</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.ComplexBlockTT.html#tltorch.ComplexBlockTT" title="tltorch.ComplexBlockTT"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplexBlockTT</span></code></a>(*args, **kwargs)</p></td>
<td><p>Complex BlockTT Factorization</p></td>
</tr>
</tbody>
</table>
<p>You can also transparently instanciate any of these using directly the main classes, <code class="docutils literal notranslate"><span class="pre">TensorizedTensor</span></code> or <code class="docutils literal notranslate"><span class="pre">FactorizedTensor</span></code> and specifying
<code class="docutils literal notranslate"><span class="pre">factorization=&quot;ComplexCP&quot;</span></code> or in general <code class="docutils literal notranslate"><span class="pre">ComplexFactorization</span></code> with <cite>Factorization</cite> any of the supported decompositions.</p>
</section>
<section id="module-tltorch.factorized_tensors">
<span id="initialization"></span><span id="init-ref"></span><h2>Initialization<a class="headerlink" href="#module-tltorch.factorized_tensors" title="Link to this heading">¶</a></h2>
<p>Initialization is particularly important in the context of deep learning.
We provide convenient functions to directly initialize factorized tensor (i.e. their factors)
such that their reconstruction follows approximately a centered Gaussian distribution.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.tensor_init.html#tltorch.factorized_tensors.init.tensor_init" title="tltorch.factorized_tensors.init.tensor_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_init</span></code></a>(tensor[, std])</p></td>
<td><p>Initializes directly the parameters of a factorized tensor so the reconstruction has the specified standard deviation and 0 mean</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.cp_init.html#tltorch.factorized_tensors.init.cp_init" title="tltorch.factorized_tensors.init.cp_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cp_init</span></code></a>(cp_tensor[, std])</p></td>
<td><p>Initializes directly the weights and factors of a CP decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.tucker_init.html#tltorch.factorized_tensors.init.tucker_init" title="tltorch.factorized_tensors.init.tucker_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_init</span></code></a>(tucker_tensor[, std])</p></td>
<td><p>Initializes directly the weights and factors of a Tucker decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.tt_init.html#tltorch.factorized_tensors.init.tt_init" title="tltorch.factorized_tensors.init.tt_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tt_init</span></code></a>(tt_tensor[, std])</p></td>
<td><p>Initializes directly the weights and factors of a TT decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_tensors.init.block_tt_init.html#tltorch.factorized_tensors.init.block_tt_init" title="tltorch.factorized_tensors.init.block_tt_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">block_tt_init</span></code></a>(block_tt[, std])</p></td>
<td><p>Initializes directly the weights and factors of a BlockTT decomposition so the reconstruction has the specified std and 0 mean</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tltorch.factorized_layers">
<span id="tensor-regression-layers"></span><span id="trl-ref"></span><h2>Tensor Regression Layers<a class="headerlink" href="#module-tltorch.factorized_layers" title="Link to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.TRL.html#tltorch.factorized_layers.TRL" title="tltorch.factorized_layers.TRL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TRL</span></code></a>(input_shape, output_shape[, bias, ...])</p></td>
<td><p>Tensor Regression Layers</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tensor-contraction-layers">
<span id="tcl-ref"></span><h2>Tensor Contraction Layers<a class="headerlink" href="#tensor-contraction-layers" title="Link to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.TCL.html#tltorch.factorized_layers.TCL" title="tltorch.factorized_layers.TCL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TCL</span></code></a>(input_shape, rank[, verbose, bias, ...])</p></td>
<td><p>Tensor Contraction Layer <a class="reference internal" href="generated/tltorch.factorized_layers.TCL.html#r4c5b93526459-1" id="id1"><span>[R4c5b93526459-1]</span></a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="factorized-linear-layers">
<span id="factorized-linear-ref"></span><h2>Factorized Linear Layers<a class="headerlink" href="#factorized-linear-layers" title="Link to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.FactorizedLinear.html#tltorch.factorized_layers.FactorizedLinear" title="tltorch.factorized_layers.FactorizedLinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedLinear</span></code></a>(in_tensorized_features, ...)</p></td>
<td><p>Tensorized Fully-Connected Layers</p></td>
</tr>
</tbody>
</table>
</section>
<section id="factorized-convolutions">
<span id="factorized-conv-ref"></span><h2>Factorized Convolutions<a class="headerlink" href="#factorized-convolutions" title="Link to this heading">¶</a></h2>
<p>General N-Dimensional convolutions in Factorized forms</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.FactorizedConv.html#tltorch.factorized_layers.FactorizedConv" title="tltorch.factorized_layers.FactorizedConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedConv</span></code></a>(in_channels, out_channels, ...)</p></td>
<td><p>Create a factorized convolution of arbitrary order</p></td>
</tr>
</tbody>
</table>
</section>
<section id="factorized-embeddings">
<span id="tensor-dropout-ref"></span><h2>Factorized Embeddings<a class="headerlink" href="#factorized-embeddings" title="Link to this heading">¶</a></h2>
<p>A drop-in replacement for PyTorch’s embeddings but using an efficient tensor parametrization that never reconstructs the full table.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.factorized_layers.FactorizedEmbedding.html#tltorch.factorized_layers.FactorizedEmbedding" title="tltorch.factorized_layers.FactorizedEmbedding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FactorizedEmbedding</span></code></a>(num_embeddings, ...[, ...])</p></td>
<td><p>Tensorized Embedding Layers For Efficient Model Compression Tensorized drop-in replacement for <cite>torch.nn.Embedding</cite></p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tltorch.tensor_hooks">
<span id="tensor-dropout"></span><span id="id2"></span><h2>Tensor Dropout<a class="headerlink" href="#module-tltorch.tensor_hooks" title="Link to this heading">¶</a></h2>
<p>These functions allow you to easily add or remove tensor dropout from tensor layers.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.tensor_dropout.html#tltorch.tensor_hooks.tensor_dropout" title="tltorch.tensor_hooks.tensor_dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_dropout</span></code></a>(factorized_tensor[, p, ...])</p></td>
<td><p>Tensor Dropout</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.remove_tensor_dropout.html#tltorch.tensor_hooks.remove_tensor_dropout" title="tltorch.tensor_hooks.remove_tensor_dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_tensor_dropout</span></code></a>(factorized_tensor)</p></td>
<td><p>Removes the tensor dropout from a TensorModule</p></td>
</tr>
</tbody>
</table>
<p>You can also use the class API below but unless you have a particular use for the classes, you should use the convenient functions provided instead.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.TensorDropout.html#tltorch.tensor_hooks.TensorDropout" title="tltorch.tensor_hooks.TensorDropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDropout</span></code></a>(proba[, min_dim, min_values, ...])</p></td>
<td><p>Decomposition Hook for Tensor Dropout on FactorizedTensor</p></td>
</tr>
</tbody>
</table>
</section>
<section id="l1-regularization">
<span id="tensor-lasso-ref"></span><h2>L1 Regularization<a class="headerlink" href="#l1-regularization" title="Link to this heading">¶</a></h2>
<p>L1 Regularization on tensor modules.</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.tensor_lasso.html#tltorch.tensor_hooks.tensor_lasso" title="tltorch.tensor_hooks.tensor_lasso"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_lasso</span></code></a>([factorization, penalty, ...])</p></td>
<td><p>Generalized Tensor Lasso from a factorized tensors</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tltorch.tensor_hooks.remove_tensor_lasso.html#tltorch.tensor_hooks.remove_tensor_lasso" title="tltorch.tensor_hooks.remove_tensor_lasso"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_tensor_lasso</span></code></a>(factorized_tensor)</p></td>
<td><p>Removes the tensor lasso from a TensorModule</p></td>
</tr>
</tbody>
</table>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Link to this heading">¶</a></h2>
<p>Utility functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tltorch.utils.get_tensorized_shape.html#tltorch.utils.get_tensorized_shape" title="tltorch.utils.get_tensorized_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tensorized_shape</span></code></a>(in_features, out_features)</p></td>
<td><p>Factorizes in_features and out_features such that: * they both are factorized into the same number of integers * they should both be factorized into <cite>order</cite> integers * each of the factors should be at least min_dim</p></td>
</tr>
</tbody>
</table>
</section>
</section>


      </div>

      
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button pagination-previous" href="../install.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Installing tensorly-Torch</span>
    </a>
    
    
    <a class="button pagination-next" href="generated/tltorch.FactorizedTensor.html" title="next page" accesskey="n">
        <span><code class="xref py py-mod docutils literal notranslate"><span class="pre">tltorch</span></code>.FactorizedTensor </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

      

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2024, Jean Kossaifi.<br/>
        </div>
      <div class="block">
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> and the <a href="http://tensorly.org"><strong>TensorLy</strong></a> theme by <a href="http://jeankossaifi.com">Jean Kossaifi</a>.
      </div>
    </div>
  </footer>

    </div>

  </div>  

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc"> 
        <p class="menu-label"> 
            <span class="icon-text">
                <span class="icon"><i class="fas fa-duotone fa-list"></i></span>
                <span> On this page </span>
            </span>
        </p>

        <div class="menu menu-list localtoc-list">
        <ul>
<li><a class="reference internal" href="#">API reference</a><ul>
<li><a class="reference internal" href="#factorized-tensors">Factorized Tensors</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#tensorized-matrices">Tensorized Matrices</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#complex-tensors">Complex Tensors</a></li>
<li><a class="reference internal" href="#module-tltorch.factorized_tensors">Initialization</a></li>
<li><a class="reference internal" href="#module-tltorch.factorized_layers">Tensor Regression Layers</a></li>
<li><a class="reference internal" href="#tensor-contraction-layers">Tensor Contraction Layers</a></li>
<li><a class="reference internal" href="#factorized-linear-layers">Factorized Linear Layers</a></li>
<li><a class="reference internal" href="#factorized-convolutions">Factorized Convolutions</a></li>
<li><a class="reference internal" href="#factorized-embeddings">Factorized Embeddings</a></li>
<li><a class="reference internal" href="#module-tltorch.tensor_hooks">Tensor Dropout</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#l1-regularization">L1 Regularization</a></li>
<li><a class="reference internal" href="#utilities">Utilities</a></li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

  

  </div>  
  </div> 

  
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>